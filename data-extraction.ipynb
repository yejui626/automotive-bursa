{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b649caa4",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb707f4",
   "metadata": {},
   "source": [
    "## DOSM Vehicle Registration Data\n",
    "\n",
    "https://data.gov.my/data-catalogue/registration_transactions_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169649f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cars_2022.parquet...\n",
      "Saved: /Users/gary/Documents/Playground/automotive-bursa/data/cars_2022.parquet\n",
      "Processing cars_2023.parquet...\n",
      "Saved: /Users/gary/Documents/Playground/automotive-bursa/data/cars_2023.parquet\n",
      "Processing cars_2024.parquet...\n",
      "Saved: /Users/gary/Documents/Playground/automotive-bursa/data/cars_2024.parquet\n",
      "Processing cars_2025.parquet...\n",
      "Saved: /Users/gary/Documents/Playground/automotive-bursa/data/cars_2025.parquet\n",
      "\n",
      "All files processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Append /data to cwd and define the target directory\n",
    "TARGET_DIR = os.path.join(cwd, 'data')\n",
    "os.makedirs(TARGET_DIR, exist_ok=True)\n",
    "\n",
    "# Define URLs and corresponding file names\n",
    "datasets = {\n",
    "    'cars_2022.parquet': 'https://storage.data.gov.my/transportation/cars_2022.parquet',\n",
    "    'cars_2023.parquet': 'https://storage.data.gov.my/transportation/cars_2023.parquet',\n",
    "    'cars_2024.parquet': 'https://storage.data.gov.my/transportation/cars_2024.parquet',\n",
    "    'cars_2025.parquet': 'https://storage.data.gov.my/transportation/cars_2025.parquet'\n",
    "}\n",
    "\n",
    "# Loop through each dataset\n",
    "for file_name, url in datasets.items():\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    target_path = os.path.join(TARGET_DIR, file_name)\n",
    "\n",
    "    # Read the parquet file from URL\n",
    "    df = pd.read_parquet(url)\n",
    "\n",
    "    # Convert 'date_reg' to datetime if it exists\n",
    "    if 'date_reg' in df.columns:\n",
    "        df['date_reg'] = pd.to_datetime(df['date_reg'], errors='coerce', format='%Y-%m-%d')\n",
    "\n",
    "    # Save to local parquet file\n",
    "    df.to_parquet(target_path, engine='fastparquet', index=True)\n",
    "    print(f\"Saved: {target_path}\")\n",
    "\n",
    "print(\"\\nAll files processed and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95582ed",
   "metadata": {},
   "source": [
    "## Bursa Automotive Sector Companies (Quarterly Results)\n",
    "\n",
    "1. DRB-HICOM Berhad (1619)\n",
    "2. Sime UMW (4588)\n",
    "3. Bermaz Auto Berhad (5248)\n",
    "4. Sime Darby (4197)\n",
    "5. Tan Chong Motor Holdings (4405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee042cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DRB-HICOM Berhad to CSV and Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Sime UMW to CSV and Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Cycle & Carriage Bintang Berhad to CSV and Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Bermaz Auto Berhad to CSV and Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Sime Darby to CSV and Parquet.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gooyt\\AppData\\Local\\Temp\\ipykernel_13860\\2895054555.py:41: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  df = pd.read_html(str(table))[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Tan Chong Motor Holdings to CSV and Parquet.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Setup headless Selenium Chrome driver\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(service=Service(), options=options)\n",
    "\n",
    "# List of stock codes and names\n",
    "stocks = {\n",
    "    \"1619\": \"DRB-HICOM Berhad\",\n",
    "    \"4588\": \"Sime UMW\",\n",
    "    \"5248\": \"Bermaz Auto Berhad\",\n",
    "    \"4197\": \"Sime Darby\",\n",
    "    \"4405\": \"Tan Chong Motor Holdings\"\n",
    "}\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://klse.i3investor.com/web/stock/financial-quarter/\"\n",
    "\n",
    "# Output folder\n",
    "output_folder = \"data/quarterly_financials\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each stock\n",
    "for code, name in stocks.items():\n",
    "    url = base_url + code\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    table = soup.find(\"table\", {\"id\": \"dttable-fin-quarter\"})\n",
    "    \n",
    "    clean_name = name.replace(\" \", \"_\").replace(\"&\", \"and\")  # Safe for filenames\n",
    "    \n",
    "    if table:\n",
    "        try:\n",
    "            df = pd.read_html(str(table))[0]\n",
    "            \n",
    "            # Save as CSV\n",
    "            csv_path = os.path.join(output_folder, f\"{clean_name}.csv\")\n",
    "            df.to_csv(csv_path, index=False)\n",
    "            \n",
    "            # Save as Parquet\n",
    "            parquet_path = os.path.join(output_folder, f\"{clean_name}.parquet\")\n",
    "            df.to_parquet(parquet_path, index=False)\n",
    "            \n",
    "            print(f\"Saved {name} to CSV and Parquet.\")\n",
    "        except ValueError:\n",
    "            print(f\"{name}: Table found but failed to parse.\")\n",
    "    else:\n",
    "        print(f\"{name}: No table found.\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4845107a",
   "metadata": {},
   "source": [
    "## Bursa Automotive Sector Companies (Stock Prices)\n",
    "\n",
    "1. DRB-HICOM Berhad (1619)\n",
    "2. Sime UMW (4588)\n",
    "3. Bermaz Auto Berhad (5248)\n",
    "4. Sime Darby (4197)\n",
    "5. Tan Chong Motor Holdings (4405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f95c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['4588.KL']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRB-HICOM Berhad data saved.\n",
      "No data found for Sime UMW (4588.KL)\n",
      "Bermaz Auto Berhad data saved.\n",
      "Sime Darby data saved.\n",
      "Tan Chong Motor Holdings data saved.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define output folder\n",
    "output_folder = \"data/stock_prices\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Ticker mapping\n",
    "companies = {\n",
    "    \"DRB-HICOM Berhad\": \"1619.KL\",\n",
    "    \"Sime UMW\": \"4588.KL\",\n",
    "    \"Bermaz Auto Berhad\": \"5248.KL\",\n",
    "    \"Sime Darby\": \"4197.KL\",\n",
    "    \"Tan Chong Motor Holdings\": \"4405.KL\"\n",
    "}\n",
    "\n",
    "# Date range\n",
    "start_date = \"2023-01-01\"\n",
    "end_date = \"2025-12-31\"\n",
    "\n",
    "# Download and save\n",
    "for name, ticker in companies.items():\n",
    "    try:\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        if not df.empty:\n",
    "            clean_name = name.replace(\" \", \"_\").replace(\"&\", \"and\")\n",
    "\n",
    "            # Save as CSV\n",
    "            df.to_csv(os.path.join(output_folder, f\"{clean_name}.csv\"))\n",
    "\n",
    "            # Save as Parquet\n",
    "            df.to_parquet(os.path.join(output_folder, f\"{clean_name}.parquet\"))\n",
    "\n",
    "            print(f\"{name} data saved.\")\n",
    "        else:\n",
    "            print(f\"No data found for {name} ({ticker})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error for {name} ({ticker}): {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fefd33",
   "metadata": {},
   "source": [
    "### SIME UMW delisted since Feb 2025\n",
    "- Downloaded Manually through investing.com (https://www.investing.com/equities/umw-holdings-bhd-historical-data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
